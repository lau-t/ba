{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook stuck?\n",
    "Note that because of Jupyter and Plotly issues, sometimes the code may stuck at visualization. We recommend **restart the kernels** and try again to see if the issue is resolved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as colors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "DATASET_ROOT = \"/path/to/dataset\"  # Specify your own dataset path\n",
    "SCENE_ID = 0  # Select a scene id\n",
    "\n",
    "dataset_path = Path(DATASET_ROOT)\n",
    "print(\"Chosen ASE data path: \", dataset_path)\n",
    "print(f\"Using Scene {SCENE_ID} for these examples\")\n",
    "\n",
    "scene_path = dataset_path / str(SCENE_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Reading Scene Annotations and 3D Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from code_snippets.readers import read_points_file, read_trajectory_file, read_language_file\n",
    "\n",
    "# Load scene point cloud using read_points_file()\n",
    "points_path = scene_path / \"semidense_points.csv.gz\"\n",
    "points = read_points_file(points_path)\n",
    "\n",
    "# Load a trajectory using read_trajectory_file() \n",
    "trajectory_path = scene_path / \"trajectory.csv\"\n",
    "trajectory = read_trajectory_file(trajectory_path)\n",
    "\n",
    "# Load a scene command language using read_language_file()\n",
    "language_path = scene_path / \"ase_scene_language.txt\"\n",
    "entities = read_language_file(language_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from code_snippets.interpreter import language_to_bboxes\n",
    "\n",
    "# Interpret scene commands into 3D Boxes\n",
    "entity_boxes = language_to_bboxes(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot each modality together in 3D\n",
    "from code_snippets.plotters import plot_point_cloud, plot_trajectory, plot_box_wireframe\n",
    "\n",
    "plot_traces = []\n",
    "# Create a trace for the pointcloud using plot_point_cloud()\n",
    "plot_traces.append(plot_point_cloud(points))\n",
    "# Create a trace for the trajectory using plot_trajectory()\n",
    "plot_traces.append(plot_trajectory(trajectory))\n",
    "\n",
    "# Create a trace for each entity box in the form of a wireframe using plot_box_wireframe()\n",
    "for entity_box in entity_boxes:\n",
    "    plot_traces.append(plot_box_wireframe(entity_box))\n",
    "\n",
    "fig = go.Figure(data=plot_traces)\n",
    "fig.update_layout(\n",
    "    template=\"plotly_dark\",\n",
    "    scene={\n",
    "        \"xaxis\": {\"showticklabels\": False, \"title\": \"\"},\n",
    "        \"yaxis\": {\"showticklabels\": False, \"title\": \"\"},\n",
    "        \"zaxis\": {\"showticklabels\": False, \"title\": \"\"},\n",
    "    },\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, we include a plotting function that will handle all of the steps for you.\n",
    "from code_snippets.plotters import plot_3d_scene\n",
    "\n",
    "plot_3d_scene(\n",
    "    language_path=language_path,\n",
    "    points_path=points_path,\n",
    "    trajectory_path=trajectory_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Loading and Plotting Images and Image Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_bright_colormap(num_colors=1024):\n",
    "    bright_colors = np.random.rand(num_colors, 3)\n",
    "    bright_colors = (bright_colors + 1) / 2\n",
    "    return colors.ListedColormap([c for c in bright_colors])\n",
    "\n",
    "scene_path = dataset_path / str(SCENE_ID)\n",
    "\n",
    "rgb_dir = scene_path / \"rgb\"\n",
    "depth_dir = scene_path / \"depth\"\n",
    "instance_dir = scene_path / \"instances\"\n",
    "\n",
    "# Choose a random frame to plot from the scene's images\n",
    "num_frames = len(list(rgb_dir.glob(\"*.jpg\")))\n",
    "frame_idx = np.random.randint(num_frames)\n",
    "\n",
    "# Load images\n",
    "frame_id = str(frame_idx).zfill(7)\n",
    "\n",
    "rgb_path = rgb_dir / f\"vignette{frame_id}.jpg\"\n",
    "depth_path = depth_dir / f\"depth{frame_id}.png\"\n",
    "instance_path = instance_dir / f\"instance{frame_id}.png\"\n",
    "\n",
    "rgb = Image.open(rgb_path)\n",
    "depth = Image.open(depth_path)\n",
    "instances = Image.open(instance_path)\n",
    "\n",
    "# Note: Images are rotated to upright for visualization.\n",
    "# However, the camera calibration is for the original orientation.\n",
    "rgb_to_plot = rgb.rotate(-90, expand=True)\n",
    "depth_to_plot = depth.rotate(-90, expand=True)\n",
    "instances_to_plot = instances.rotate(-90, expand=True)\n",
    "\n",
    "# Plot the images\n",
    "fig, axes = plt.subplots(ncols=3, nrows=1, figsize=(15, 5), dpi=300)\n",
    "axes[0].imshow(rgb_to_plot)\n",
    "axes[0].set_title(\"RGB Image\")\n",
    "axes[1].imshow(np.array(depth_to_plot), cmap=\"plasma\")\n",
    "axes[1].set_title(\"Metric Depth (mm)\")\n",
    "axes[2].imshow(np.array(instances_to_plot), cmap=random_bright_colormap())\n",
    "axes[2].set_title(\"Instance Map\")\n",
    "for ax in axes:\n",
    "    ax.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Project Points into Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from projectaria_tools.projects import ase\n",
    "\n",
    "def transform_3d_points(transform, points):\n",
    "    N = len(points)\n",
    "    points_h = np.concatenate([points, np.ones((N, 1))], axis=1)\n",
    "    transformed_points_h = (transform @ points_h.T).T\n",
    "    transformed_points = transformed_points_h[:, :-1]\n",
    "    return transformed_points\n",
    "    \n",
    "# Load camera calibration\n",
    "device = ase.get_ase_rgb_calibration()\n",
    "\n",
    "# Load the trajectory using read_trajectory_file() \n",
    "trajectory_path = scene_path / \"trajectory.csv\"\n",
    "trajectory = read_trajectory_file(trajectory_path)\n",
    "\n",
    "# Load scene point cloud using read_points_file()\n",
    "points_path = scene_path / \"semidense_points.csv.gz\"\n",
    "points_world = read_points_file(points_path)\n",
    "\n",
    "# Choose and load random frame to plot from the scene's images\n",
    "num_frames = len(list(rgb_dir.glob(\"*.jpg\")))\n",
    "frame_idx = np.random.randint(num_frames)\n",
    "frame_id = str(frame_idx).zfill(7)\n",
    "rgb_path = rgb_dir / f\"vignette{frame_id}.jpg\"\n",
    "rgb = Image.open(rgb_path)\n",
    "\n",
    "# Transform the points into the device coordinate frame\n",
    "T_world_from_device = trajectory[\"Ts_world_from_device\"][frame_idx]\n",
    "T_device_from_world = np.linalg.inv(T_world_from_device)\n",
    "points_device = transform_3d_points(T_device_from_world, points_world)\n",
    "\n",
    "# Transform the points into the RGB camera coordinate frame\n",
    "T_device_from_camera = device.get_transform_device_camera().to_matrix()\n",
    "T_camera_from_device = np.linalg.inv(T_device_from_camera)\n",
    "points_device = transform_3d_points(T_camera_from_device, points_device)\n",
    "\n",
    "# Project points into the image\n",
    "points_image = []\n",
    "depths = []\n",
    "for point_device in points_device:\n",
    "    point_image = device.project(point_device)\n",
    "    if point_image is not None:\n",
    "        points_image.append(point_image)\n",
    "points_image = np.stack(points_image)\n",
    "\n",
    "# Overlay projected points onto image\n",
    "plt.imshow(rgb)\n",
    "plt.scatter(points_image[:, 0], points_image[:, 1], s=0.01, alpha=0.3, c=\"#FFFFFF\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
