{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a005f19",
   "metadata": {},
   "source": [
    "# Submission Validation\n",
    "## for Project Aria 3D Object Detection Challenges\n",
    "\n",
    "This tutorial will load the example submission file and visualize it. Participants can use this notebook to validate their submission files before submitting to the eval.ai website. \n",
    "\n",
    "### Notebook stuck?\n",
    "Note that because of Jupyter and Plotly issues, sometimes the code may stuck at visualization. We recommend **restart the kernels** and try again to see if the issue is resolved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f387f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "import numpy as np\n",
    "\n",
    "from projectaria_tools.core.stream_id import StreamId\n",
    "from projectaria_tools.projects.adt import (\n",
    "   AriaDigitalTwinDataProvider,\n",
    "   AriaDigitalTwinDataPathsProvider,\n",
    ")\n",
    "from projectaria_tools.projects.adt.utils import (\n",
    "    VERTICES_AXIS, \n",
    "    get_timed_homo_poses,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6659b147",
   "metadata": {},
   "source": [
    "### Select a phase, a submission file, and a sequence for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97be46ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase = \"example\"\n",
    "example_root = os.path.expanduser('~') + \"/Documents/bug_bash_adt\"\n",
    "\n",
    "sequence_name = \"Apartment_release_challenge_example\"\n",
    "sequence_folder = os.path.join(example_root, sequence_name)\n",
    "submission_file = os.path.join(sequence_folder, \"submissions_annotations_example\", \"annotations_example.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af08d1d4",
   "metadata": {},
   "source": [
    "### Load the sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01ec7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_provider = AriaDigitalTwinDataPathsProvider(sequence_folder)\n",
    "selected_device_number = 0\n",
    "data_paths = paths_provider.get_datapaths_by_device_num(selected_device_number)\n",
    "\n",
    "gt_provider = AriaDigitalTwinDataProvider(data_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edf219e",
   "metadata": {},
   "source": [
    "### Load all predicted poses and timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c472761",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_archive = zipfile.ZipFile(\n",
    "    submission_file, mode=\"r\", compression=zipfile.ZIP_BZIP2\n",
    ")\n",
    "predicted_poses = get_timed_homo_poses(\n",
    "    submission_archive, \n",
    "    sequence_name\n",
    ")\n",
    "\n",
    "rgb_streamid = \"214-1\"\n",
    "stream_id = StreamId(rgb_streamid)\n",
    "img_timestamps_ns = gt_provider.get_aria_device_capture_timestamps_ns(stream_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26bd95f",
   "metadata": {},
   "source": [
    "### Visualize the predicted pose on the image given a timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475cfa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# choose the frame in the middle of the sequence\n",
    "select_timestamps_ns = img_timestamps_ns[50]\n",
    "\n",
    "image_with_dt = gt_provider.get_aria_image_by_timestamp_ns(select_timestamps_ns, stream_id)\n",
    "\n",
    "# check image is valid. It's always possible that the data retrieval fails, therefore all\n",
    "# returned data not only contains dt, but also contains an isValid() function, or returns\n",
    "# an optional variable.\n",
    "assert image_with_dt.is_valid(), \"Image not valid!\"\n",
    "\n",
    "# convert image to numpy array\n",
    "image = image_with_dt.data().to_numpy_array()\n",
    "\n",
    "plt.figure(figsize=[6, 6])\n",
    "plt.imshow(image)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# get the Aria pose\n",
    "aria3dpose_with_dt = gt_provider.get_aria_3d_pose_by_timestamp_ns(select_timestamps_ns)\n",
    "if not aria3dpose_with_dt.is_valid():\n",
    "    print(\"aria 3d pose is not available\")\n",
    "aria3dpose = aria3dpose_with_dt.data()\n",
    "\n",
    "# now to project 3D bbox to Aria camera\n",
    "# get 6DoF object pose with repect to the target camera\n",
    "transform_cam_device = gt_provider.get_aria_transform_device_camera(stream_id).inverse()\n",
    "transform_cam_scene = np.matmul(\n",
    "    transform_cam_device.to_matrix(), aria3dpose.transform_scene_device.inverse().to_matrix()\n",
    ")\n",
    "\n",
    "# get projection function\n",
    "cam_calibration = gt_provider.get_aria_camera_calibration(stream_id)\n",
    "assert cam_calibration is not None, \"no camera calibration\"\n",
    "\n",
    "for proto, poses in predicted_poses[select_timestamps_ns].items():\n",
    "    for transform_scene_obj in poses:\n",
    "        transform_cam_obj = transform_cam_scene @ transform_scene_obj\n",
    "        # Draw Axis\n",
    "        vertices_i = []\n",
    "        skip = False\n",
    "        for vertice_o in VERTICES_AXIS:\n",
    "            vertice_c = transform_cam_obj[:3, :3] @ vertice_o + transform_cam_obj[:3, 3]\n",
    "            vertice_i = cam_calibration.project(vertice_c)\n",
    "            if vertice_i is None:\n",
    "                skip = True\n",
    "            else:\n",
    "                vertices_i.append(vertice_i)\n",
    "        if skip:\n",
    "            print(f\"{proto} is skipped for visualization due to outside of image.\")\n",
    "            continue\n",
    "        vertices_i = np.stack(vertices_i)\n",
    "        plt.plot(\n",
    "            [int(vertices_i[0, 0]), int(vertices_i[1, 0])],\n",
    "            [int(vertices_i[0, 1]), int(vertices_i[1, 1])],\n",
    "            c=\"r\",\n",
    "        )\n",
    "        plt.plot(\n",
    "            [int(vertices_i[0, 0]), int(vertices_i[2, 0])],\n",
    "            [int(vertices_i[0, 1]), int(vertices_i[2, 1])],\n",
    "            c=\"g\",\n",
    "        )\n",
    "        plt.plot(\n",
    "            [int(vertices_i[0, 0]), int(vertices_i[3, 0])],\n",
    "            [int(vertices_i[0, 1]), int(vertices_i[3, 1])],\n",
    "            c=\"b\",\n",
    "        )\n",
    "        plt.text(\n",
    "            int(vertices_i[0, 0]), int(vertices_i[0, 1]), proto, c=\"y\", fontsize=6\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1004e615",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
